{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RNN, device, SampleMetroDataset, ForecastMetroDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 73, 80, 2]) torch.Size([7, 73, 80, 2])\n",
      "torch.Size([32, 20, 2]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Exo 2\n",
    "\n",
    "# Nombre de stations utilisé (dim de output)\n",
    "CLASSES = 10\n",
    "#Longueur des séquences\n",
    "LENGTH = 20\n",
    "# Dimension de l'entrée (1 (in) ou 2 (in/out))\n",
    "DIM_INPUT = 2\n",
    "#Taille du batch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH = \"../data/\"\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\",\"rb\"),  weights_only=True)\n",
    "# matrix_train, matrix_test = torch.load(open(\"/home/wujinyi/sorbonnefile/AMAL/student_tp3/data/hzdataset.pch\",\"rb\"), weights_only=True)\n",
    "\n",
    "ds_train = SampleMetroDataset(matrix_train[:, :, :CLASSES, :DIM_INPUT], length = LENGTH)\n",
    "ds_test = SampleMetroDataset(matrix_test[:, :, :CLASSES, :DIM_INPUT], length = LENGTH, stations_max = ds_train.stations_max)\n",
    "data_train = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "data_test = DataLoader(ds_test, batch_size=BATCH_SIZE,shuffle=False)\n",
    "print(matrix_train.size(), matrix_test.size())\n",
    "for x_batch, y_batch in data_train:\n",
    "    print(x_batch.size(), y_batch.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0684, Accuracy: 19.91%\n",
      "Epoch 2, Loss: 0.0621, Accuracy: 29.69%\n",
      "Epoch 3, Loss: 0.0606, Accuracy: 29.21%\n",
      "Epoch 4, Loss: 0.0599, Accuracy: 28.89%\n",
      "Epoch 5, Loss: 0.0596, Accuracy: 30.36%\n",
      "Epoch 6, Loss: 0.0574, Accuracy: 35.23%\n",
      "Epoch 7, Loss: 0.0568, Accuracy: 38.95%\n",
      "Epoch 8, Loss: 0.0560, Accuracy: 42.20%\n",
      "Epoch 9, Loss: 0.0556, Accuracy: 42.32%\n",
      "Epoch 10, Loss: 0.0551, Accuracy: 43.61%\n",
      "Epoch 11, Loss: 0.0550, Accuracy: 44.06%\n",
      "Epoch 12, Loss: 0.0546, Accuracy: 45.15%\n",
      "Epoch 13, Loss: 0.0542, Accuracy: 46.66%\n",
      "Epoch 14, Loss: 0.0539, Accuracy: 46.67%\n",
      "Epoch 15, Loss: 0.0538, Accuracy: 46.72%\n",
      "Epoch 16, Loss: 0.0534, Accuracy: 47.92%\n",
      "Epoch 17, Loss: 0.0533, Accuracy: 48.14%\n",
      "Epoch 18, Loss: 0.0534, Accuracy: 48.40%\n",
      "Epoch 19, Loss: 0.0530, Accuracy: 50.16%\n",
      "Epoch 20, Loss: 0.0528, Accuracy: 50.21%\n"
     ]
    }
   ],
   "source": [
    "#  TODO:  Question 2 : prédiction de la ville correspondant à une séquence\n",
    "DIM_HIDDEN = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "model = RNN(DIM_INPUT, DIM_HIDDEN, CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x_batch, y_batch in data_train:\n",
    "        batch_size = y_batch.size(0)\n",
    "        x_batch = x_batch.transpose(0,1)\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        h_0 = torch.zeros(batch_size,DIM_HIDDEN).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        h_seq = model(x_batch, h_0)\n",
    "        y_pred = model.decode(h_seq[-1])\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += batch_size\n",
    "        total_loss += loss.item()\n",
    "        correct += (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct/total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exo 3\n",
    "\n",
    "# Nombre de stations utilisé\n",
    "CLASSES = 10\n",
    "#Longueur des séquences\n",
    "LENGTH = 20\n",
    "# Dimension de l'entrée (1 (in) ou 2 (in/out))\n",
    "DIM_INPUT = 2\n",
    "#Taille du batch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH = \"../data/\"\n",
    "\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\", \"rb\"), weights_only=True)\n",
    "ds_train = ForecastMetroDataset(\n",
    "    matrix_train[:, :, :CLASSES, :DIM_INPUT], length=LENGTH)\n",
    "ds_test = ForecastMetroDataset(\n",
    "    matrix_test[:, :, :CLASSES, :DIM_INPUT], length=LENGTH, stations_max=ds_train.stations_max)\n",
    "data_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "data_test = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0011\n",
      "Epoch 2, Loss: 0.0007\n",
      "Epoch 3, Loss: 0.0005\n",
      "Epoch 4, Loss: 0.0004\n",
      "Epoch 5, Loss: 0.0004\n",
      "Epoch 6, Loss: 0.0003\n",
      "Epoch 7, Loss: 0.0003\n",
      "Epoch 8, Loss: 0.0003\n",
      "Epoch 9, Loss: 0.0003\n",
      "Epoch 10, Loss: 0.0003\n",
      "Epoch 11, Loss: 0.0003\n",
      "Epoch 12, Loss: 0.0002\n",
      "Epoch 13, Loss: 0.0002\n",
      "Epoch 14, Loss: 0.0002\n",
      "Epoch 15, Loss: 0.0002\n",
      "Epoch 16, Loss: 0.0002\n",
      "Epoch 17, Loss: 0.0002\n",
      "Epoch 18, Loss: 0.0002\n",
      "Epoch 19, Loss: 0.0002\n",
      "Epoch 20, Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "DIM_HIDDEN = 64\n",
    "EPOCHS = 20 \n",
    "\n",
    "model_m2m = RNN(DIM_INPUT, DIM_HIDDEN, DIM_INPUT).to(device)\n",
    "optimizer = torch.optim.Adam(model_m2m.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_m2m.train()\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    for x_batch, y_batch in data_train:\n",
    "        batch_size = y_batch.size(0)\n",
    "        x_batch = x_batch.transpose(0,1)\n",
    "        y_batch = y_batch.transpose(0,1)\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        h_0 = torch.zeros(size=(batch_size, CLASSES, DIM_HIDDEN)).to(device)\n",
    "\n",
    "        h_seq = model_m2m(x_batch, h_0)\n",
    "        y_pred = model_m2m.decode(h_seq)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += batch_size\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
