{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import time\n",
    "import re\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# FILE = \"../data/en-fra.txt\"\n",
    "FILE = \"/home/wujinyi/sorbonnefile/AMAL/student_tp5/data/en-fra.txt\"\n",
    "\n",
    "writer = SummaryWriter(\"/tmp/runs/tag-\"+time.asctime())\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    正规化字符串\n",
    "    将文本中的非 ASCII 字符替换为空格，并且带有字符串正规化\n",
    "    去除带有许多空格的缩进\n",
    "    \"\"\"\n",
    "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    PAD = 0  # 补充的标识\n",
    "    EOS = 1  # 完成标识\n",
    "    SOS = 2  # 起始标识\n",
    "    OOVID = 3  # 表示未知词\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        self.oov = oov  # 是否允许OOV\n",
    "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]  # 初始化词表中的一些特殊标识\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}  # 初始化字典的转换\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        # 如果词存在于词典中，则返回它的ID\n",
    "        # 如果未知词，返回OOV的ID\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            # 试图返回词的ID\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            # 如果不存在这个词，并且允许添加，则将这个词添加到词典中\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回词表的长度\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        # 根据索引返回字\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        # 返回索引列表对应的词列表\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "# 实现两语言互译数据集的类\n",
    "class TradDataset():\n",
    "    def __init__(self, data, vocOrig, vocDest, adding=True, max_len=10):\n",
    "        self.sentences = []\n",
    "        for s in tqdm(data.split(\"\\n\")):\n",
    "            # 空行跳过\n",
    "            if len(s) < 1:\n",
    "                continue\n",
    "            # 将数据分割为原文和目标文本，并正规化\n",
    "            orig, dest = map(normalize, s.split(\"\\t\")[:2])\n",
    "            # 过长的序列跳过\n",
    "            if len(orig) > max_len:\n",
    "                continue\n",
    "            # 将字转换为ID并添加EOS标识，把数据存储到数据集中\n",
    "            self.sentences.append((torch.tensor([vocOrig.get(o) for o in orig.split(\" \")] + [Vocabulary.EOS]),\n",
    "                                  torch.tensor([vocDest.get(o) for o in dest.split(\" \")] + [Vocabulary.EOS])))\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的大小\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 返回指定索引的双语言对\n",
    "        return self.sentences[i]\n",
    "\n",
    "\n",
    "# 举行补充的 collate 函数\n",
    "# 用于将不同长度的序列补充为等长序列，并返回其与原文和目标的长度\n",
    "def collate_fn(batch):\n",
    "    orig, dest = zip(*batch)\n",
    "    o_len = torch.tensor([len(o) for o in orig])\n",
    "    d_len = torch.tensor([len(d) for d in dest])\n",
    "    return pad_sequence(orig), o_len, pad_sequence(dest), d_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1366/1366 [00:00<00:00, 3800.00it/s]\n",
      "100%|██████████| 342/342 [00:00<00:00, 6105.61it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 打开文件，读取数据\n",
    "with open(FILE) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 42  # 你可以选择任何整数作为随机种子\n",
    "torch.manual_seed(seed)  # 设置 PyTorch 的随机种子\n",
    "# 随机打乱数据\n",
    "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
    "# 训练集与测试集的分割，训练集80%\n",
    "idxTrain = int(0.8 * len(lines)*0.01)\n",
    "\n",
    "# 创建英文和法文词汇表\n",
    "vocEng = Vocabulary(True)\n",
    "vocFra = Vocabulary(True)\n",
    "MAX_LEN = 100  # 序列的最大长度\n",
    "BATCH_SIZE = 100  # Batch Size\n",
    "\n",
    "# 创建训练数据集和测试数据集\n",
    "# 通过 TradDataset 来创建数据集，中间包含转换词汇和EOS标识\n",
    "\n",
    "datatrain = TradDataset(\"\".join(lines[:idxTrain]), vocEng, vocFra, max_len=MAX_LEN)\n",
    "datatest = TradDataset(\"\".join(lines[idxTrain:int(len(lines)*0.01)]), vocEng, vocFra, max_len=MAX_LEN)\n",
    "\n",
    "# 使用 DataLoader 带有 collate_fn 来加载数据，配置 batch_size\n",
    "train_loader = DataLoader(datatrain, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(datatest, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  41,  131,   71,  ...,    4,   66,   46],\n",
      "        [  11,  132,   10,  ...,   34,  307,   11],\n",
      "        [ 761,   11, 1572,  ...,   35,   95,  146],\n",
      "        ...,\n",
      "        [   0,  143,    0,  ...,    0,    0,    0],\n",
      "        [   0,    1,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]]) torch.Size([19, 100])\n",
      "tensor([ 7, 18, 10, 15, 10,  6, 11,  8,  4,  7, 16,  6, 11, 11,  6,  7,  7, 12,\n",
      "         8,  8,  9,  5,  5,  7,  6,  8,  6,  7, 11,  5, 19, 10,  8,  5,  5,  9,\n",
      "         5, 11,  4, 13,  9,  8,  5,  5,  5, 10,  9,  8,  8, 12,  6, 11,  8,  8,\n",
      "         8,  8,  8, 11,  7,  6,  7, 10,  8,  8,  6, 10,  6,  8,  7,  6, 11, 12,\n",
      "         6,  6,  6,  8, 12,  7,  5, 10,  6,  6,  9,  7, 11,  5,  9,  8,  8,  6,\n",
      "         4,  5, 10,  7,  9, 11, 10,  7,  7,  7]) torch.Size([100])\n",
      "tensor([[ 703,  145,   81,  ...,    4,   45,  155],\n",
      "        [  13,  146, 1101,  ...,   37,  692,   13],\n",
      "        [1476,   55, 1591,  ...,   58,  207,  176],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]]) torch.Size([21, 100])\n",
      "tensor([ 6, 11, 11, 19,  9,  6, 11, 11,  4,  9, 13,  6, 10,  9,  7, 10,  7, 14,\n",
      "         9,  8, 10,  5,  7,  9,  7, 12,  6,  9, 10,  5, 21,  9,  8,  5,  7, 10,\n",
      "         4, 12,  7, 15, 12,  9,  4,  6,  8, 11,  8,  7, 10, 13,  7, 11, 11,  7,\n",
      "        12, 10,  8, 10,  6,  5,  5, 13, 11,  8,  6, 11,  9,  9,  7,  5,  9, 13,\n",
      "         7,  7,  7, 10, 16,  7,  6, 10,  7,  7, 10,  7, 11,  5, 11,  8,  9,  7,\n",
      "         6,  5, 12,  8,  7, 10,  5,  7,  7,  7]) torch.Size([100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "for orig, o_len, dest, d_len in tqdm(train_loader):\n",
    "    print(orig,orig.shape)  # 从dataloader里输出打乱后的数据，每个句子竖着排列，总共100列(batch size),每次都是随机的\n",
    "    print(o_len, o_len.shape)  # 从dataloader里输出每个数据的长度，总共100个(batch size)\n",
    "    print(dest, dest.shape)\n",
    "    print(d_len, d_len.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 翻译任务\n",
    "\n",
    "在翻译任务中，我们将使用两个RNN模型：\n",
    "\n",
    "一个编码器，用于在读取待翻译的序列后生成隐藏状态。\n",
    "\n",
    "一个解码器，从隐藏状态开始，生成翻译后的句子。\n",
    "\n",
    "除了EOS（序列结束）标记外，还需要一个特殊的SOS（序列开始）标记，作为输入给解码器的第一个标记（加上隐藏状态），从而开始翻译句子。\n",
    "\n",
    "训练解码器有两种方式：\n",
    "\n",
    "受约束模式（或称为教师强制，teacher forcing），在该模式下，将目标句子传递给解码器，每个时间步都会考虑目标句子中的一个单词：生成过程受到指导，可以精确修正每个生成的隐藏状态。\n",
    "\n",
    "非受约束模式，在迭代生成翻译时不考虑目标句子：每个时间步引入的是前一个时间步中隐藏状态解码后具有最大概率的单词（或从该分布中随机抽取一个）。这种模式像是在推理阶段生成句子，然后在整个句子生成完成后再进行修正。\n",
    "\n",
    "非受约束模式比受约束模式更困难：在预测某个单词时的错误会极大地扰乱后续的生成，并且反向传播在随后的序列中效果不佳。然而，这种方式可以更好地泛化，避免记住具体的例子。直观上来说，我们应该在训练开始时使用受约束模式来很好地初始化解码器，然后逐步切换到非受约束模式。这种过程被称为课程学习（Curriculum Learning）。\n",
    "\n",
    "问题2\n",
    "\n",
    "在 tp5-traduction.py 中实现编码器-解码器。对于编码器和解码器，使用GRU，并采用以下架构：\n",
    "\n",
    "编码器：对原始词汇表进行嵌入，然后使用GRU处理嵌入序列。\n",
    "\n",
    "解码器：对目标词汇表进行嵌入，然后使用GRU，再接一个线性网络来解码隐藏状态（最后加一个softmax）。\n",
    "\n",
    "在解码器中，你需要一个名为 generate(hidden, lenseq=None) 的方法，该方法从隐藏状态 hidden（以及作为输入的SOS标记）生成一个序列，直到达到指定长度 lenseq，或者生成了EOS标记。\n",
    "\n",
    "使用课程学习的简单策略来实现训练循环，即对于每个小批量，随机均匀地选择受约束模式或非受约束模式。在非受约束模式下生成时，可以传递目标句子的期望长度。\n",
    "\n",
    "训练你的模型，并保留一个测试集来验证是否存在过拟合或欠拟合。\n",
    "\n",
    "使用（在测试中）前一个实验中的生成方法来可视化生成的翻译。\n",
    "\n",
    "附加说明\n",
    "\n",
    "在原始论文中，两种模式的选择是基于受约束模式概率递减的方式来进行的，并且这种选择在每个时间步而不是整个小批量上进行。你可以通过改进策略并比较结果来获得额外的分数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[6., 6., 6., 6., 6.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [7., 7., 7., 7., 7.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [8., 8., 8., 8., 8.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [9., 9., 9., 9., 9.]]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))\n",
      "packed_output: PackedSequence(data=tensor([[-0.1272, -0.0329, -0.6789,  0.0133, -0.9074, -0.6769, -0.1986],\n",
      "        [-0.2959, -0.1203, -0.3401,  0.0901, -0.5296, -0.6026, -0.3728],\n",
      "        [-0.2473, -0.2140, -0.0594,  0.2074, -0.0557, -0.4280, -0.4615],\n",
      "        [-0.2134, -0.0505, -0.8804,  0.0211, -0.9799, -0.9055, -0.3184],\n",
      "        [-0.4578, -0.1782, -0.6916,  0.1385, -0.7901, -0.8654, -0.5332],\n",
      "        [-0.4265, -0.3085, -0.3518,  0.3342, -0.3207, -0.7512, -0.6517],\n",
      "        [-0.2696, -0.0609, -0.9265,  0.0253, -0.9919, -0.9750, -0.3941],\n",
      "        [-0.5579, -0.2120, -0.8383,  0.1642, -0.9081, -0.9591, -0.6241],\n",
      "        [-0.3066, -0.0669, -0.9491,  0.0275, -0.9964, -0.9940, -0.4438]],\n",
      "       grad_fn=<CatBackward0>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))\n",
      "hidden shape: torch.Size([1, 3, 7])\n",
      "hidden: tensor([[[-0.4265, -0.3085, -0.3518,  0.3342, -0.3207, -0.7512, -0.6517],\n",
      "         [-0.5579, -0.2120, -0.8383,  0.1642, -0.9081, -0.9591, -0.6241],\n",
      "         [-0.3066, -0.0669, -0.9491,  0.0275, -0.9964, -0.9940, -0.4438]]],\n",
      "       grad_fn=<IndexSelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "# 定义GRU层\n",
    "embedding_dim = 5  # 嵌入维度\n",
    "hidden_dim = 7     # 隐藏层维度\n",
    "gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "# 假设批次中有3个序列，嵌入维度为5\n",
    "embedded = torch.tensor([\n",
    "    [[1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]],  # 序列1: 实际长度为2\n",
    "    [[3, 3, 3, 3, 3], [4, 4, 4, 4, 4], [5, 5, 5, 5, 5], [0, 0, 0, 0, 0]],  # 序列2: 实际长度为3\n",
    "    [[6, 6, 6, 6, 6], [7, 7, 7, 7, 7], [8, 8, 8, 8, 8], [9, 9, 9, 9, 9]]   # 序列3: 实际长度为4\n",
    "], dtype=torch.float32)  # 形状为 (batch_size, seq_length, embedding_dim) -> (3, 4, 5)\n",
    "\n",
    "# 每个序列的实际长度\n",
    "lengths = torch.tensor([2, 3, 4])\n",
    "\n",
    "# 打包序列\n",
    "packed_input = rnn_utils.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "print(packed_input)\n",
    "\n",
    "# 通过GRU计算输出\n",
    "packed_output, hidden = gru(packed_input)\n",
    "\n",
    "print(\"packed_output:\", packed_output)\n",
    "print(\"hidden shape:\", hidden.shape)\n",
    "print(\"hidden:\", hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: 实现编码器、解码器和训练循环\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # 词嵌入层，将词汇表中的每个词映射为固定大小的向量\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=Vocabulary.PAD)\n",
    "        # GRU层，用于处理嵌入的序列并生成隐藏状态\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: 输入的词序列，lengths: 每个序列的长度\n",
    "        # print(\"encoder x:\",x.shape)\n",
    "        embedded = self.embedding(x)  # 将输入序列映射为嵌入表示  # (batch_size, seq_len, embedding_dim)\n",
    "        # print(\"encoder embedded:\",embedded.shape)\n",
    "        # print(lengths)\n",
    "        # lengths = torch.clamp(lengths, max=embedded.size(1))  # 将所有长度限制在 seq_len 范围内，可以确保没有长度超出序列的范围，避免越界错误\n",
    "        # print(lengths)\n",
    "        # 将嵌入表示打包为压缩格式，以便GRU忽略填充部分\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)  # (batch_size, seq_len, embedding_dim)\n",
    "        # 通过GRU计算隐藏状态\n",
    "        packed_output, hidden = self.gru(packed_input)  # hidden: (1, batch_size, hidden_dim)\n",
    "        # print(\"encoder hidden:\",hidden.shape)\n",
    "        return hidden  # 返回最后的隐藏状态\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 词嵌入层，将目标语言中的每个词映射为固定大小的向量\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=Vocabulary.PAD)\n",
    "        # GRU层，用于处理嵌入的输入和隐藏状态\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # 全连接层，用于将GRU的输出映射到词汇表大小的向量上\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        # 使用log softmax来计算每个词的概率\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: 输入词序列, hidden: 上一步的隐藏状态\n",
    "        embedded = self.embedding(x).unsqueeze(1)  # (batch_size, 1, embedding_dim)\n",
    "        # embedded = self.embedding(x)  # (batch_size, 1, embedding_dim)\n",
    "        # print(\"decoder embedded:\",embedded.shape)\n",
    "        # print(\"decoder hidden:\", hidden.shape)  #(num_layers=1, batch_size, hidden_dim)   \n",
    "        output, hidden = self.gru(embedded, hidden)  # 通过GRU计算输出和更新后的隐藏状态\n",
    "        output = self.fc(output)  # 全连接层映射到词汇表大小\n",
    "        output = self.softmax(output)  # 计算词的概率分布\n",
    "        return output, hidden  # 返回输出和更新后的隐藏状态\n",
    "\n",
    "    def generate(self, hidden, max_len, sos_token, eos_token):\n",
    "        # 根据初始隐藏状态生成输出序列\n",
    "        inputs = torch.tensor([[sos_token]]).to(device)  # 起始输入为SOS标记\n",
    "        outputs = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden = self(inputs, hidden)  # 通过GRU生成输出\n",
    "            topv, topi = output.topk(1)  # 选择概率最大的词\n",
    "            outputs.append(topi.item())  # 将生成的词添加到输出序列中\n",
    "            if topi.item() == eos_token:  # 如果生成EOS标记，停止生成\n",
    "                break\n",
    "            inputs = topi.squeeze().detach()  # 下一个输入是当前时间步生成的词\n",
    "        return outputs  # 返回生成的序列\n",
    "\n",
    "\n",
    "def train_model(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for orig, o_len, dest, d_len in tqdm(train_loader):\n",
    "            # 将输入数据和目标数据转移到设备上（如GPU）\n",
    "            orig = orig.transpose(0,1)\n",
    "            dest = dest.transpose(0,1)\n",
    "            # print(\"orig:\",orig.shape)\n",
    "            # print(\"dest:\",dest.shape)\n",
    "            orig, dest = orig.to(device), dest.to(device)\n",
    "            o_len, d_len = o_len.to(device), d_len.to(device)\n",
    "\n",
    "            # 梯度清零\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播通过编码器\n",
    "            # print(\"encoder:\", orig.shape)\n",
    "            # print(\"o_len:\", o_len.shape)\n",
    "            hidden = encoder(orig, o_len)\n",
    "            # print(\"hidden:\", hidden.shape)\n",
    "\n",
    "            # 初始化解码器的输入为SOS标记，隐藏状态为编码器的最后隐藏状态\n",
    "            decoder_input = torch.tensor([Vocabulary.SOS] * dest.size(0)).to(device)\n",
    "            decoder_hidden = hidden\n",
    "\n",
    "            loss = 0\n",
    "            # 随机决定是否使用teacher forcing\n",
    "            use_teacher_forcing = True if torch.rand(1).item() > 0.5 else False\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # 使用teacher forcing: 每次将目标词作为下一步的输入\n",
    "                # for di in range(dest.size(0)):\n",
    "                for di in range(dest.size(1)):\n",
    "                    # print(\"decoder_input:\", decoder_input.shape)\n",
    "                    # print(\"decoder_hidden:\", decoder_hidden.shape)\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    # print(\"decoder output:\", decoder_output.shape)\n",
    "                    # print(\"dest:\", dest[:, di].shape)\n",
    "                    # decoder_input = dest[di]  # 下一步的输入是实际目标\n",
    "                    # loss += criterion(decoder_output.squeeze(1), dest[di])\n",
    "                    decoder_input = dest[:, di]  # 下一步的输入是实际目标\n",
    "                    loss += criterion(decoder_output.squeeze(1), dest[:, di])\n",
    "            else:\n",
    "                # 不使用teacher forcing: 使用解码器自己的预测作为下一步的输入\n",
    "                # for di in range(dest.size(0)):\n",
    "                for di in range(dest.size(1)):\n",
    "                    # print(\"decoder_input:\", decoder_input.shape)\n",
    "                    # print(\"decoder_hidden:\", decoder_hidden.shape)\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    topv, topi = decoder_output.topk(1)  # 选择概率最大的词\n",
    "                    decoder_input = topi.squeeze().detach()  # 使用当前预测作为下一个时间步的输入\n",
    "                    # print(\"decoder input:\", decoder_input.shape)\n",
    "                    # print(\"decoder output:\", decoder_output.shape)\n",
    "                    # print(\"dest:\", dest[:, di].shape)\n",
    "                    # loss += criterion(decoder_output.squeeze(1), dest[di])\n",
    "                    loss += criterion(decoder_output.squeeze(1), dest[:, di])\n",
    "                    # if decoder_input.item() == Vocabulary.EOS:  # 如果生成EOS标记，停止解码\n",
    "                    #     break\n",
    "\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() / dest.size(0)\n",
    "\n",
    "        # 打印每个epoch的损失\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(encoder, decoder, test_loader, criterion, max_len):\n",
    "    encoder.eval()  # 设置为评估模式\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for orig, o_len, dest, d_len in tqdm(test_loader):\n",
    "            orig = orig.transpose(0,1)\n",
    "            dest = dest.transpose(0,1)\n",
    "            orig, dest = orig.to(device), dest.to(device)\n",
    "            o_len, d_len = o_len.to(device), d_len.to(device)\n",
    "\n",
    "            # 前向传播通过编码器\n",
    "            # print(orig)\n",
    "            # print(o_len)\n",
    "            # o_len = torch.clamp(o_len, max=orig.size(1))\n",
    "            hidden = encoder(orig, o_len)\n",
    "            # decoder_input = torch.tensor([[Vocabulary.SOS]] * dest.size(1)).to(device)\n",
    "            decoder_input = torch.tensor([Vocabulary.SOS] * dest.size(0)).to(device)\n",
    "            decoder_hidden = hidden\n",
    "            loss = 0\n",
    "\n",
    "            # 逐步生成输出序列\n",
    "            # for di in range(dest.size(0)):\n",
    "            for di in range(dest.size(1)):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)  # 选择概率最大的词\n",
    "                decoder_input = topi.squeeze().detach()  # 使用自己的预测作为下一个时间步的输入\n",
    "                loss += criterion(decoder_output.squeeze(1), dest[:, di])\n",
    "                # if decoder_input.item() == Vocabulary.EOS:  # 如果生成EOS标记，停止解码\n",
    "                #     break\n",
    "\n",
    "            total_loss += loss.item() / dest.size(0)\n",
    "\n",
    "    # 打印测试集上的损失\n",
    "    print(f\"Test Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 17.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:16<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 14.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:21<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 13.5466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 12.8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:17<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 11.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 11.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:20<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 10.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 10.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 9.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 8.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:10<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 7.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:10<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 8.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:10<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 7.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 7.6308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 7.8322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 6.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:08<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 7.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 6.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:12<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 6.3126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 4.7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "encoder = Encoder(len(vocEng), embedding_dim, hidden_dim).to(device)\n",
    "decoder = Decoder(len(vocFra), embedding_dim, hidden_dim).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=Vocabulary.PAD)  # 忽略填充部分的损失\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 20\n",
    "train_model(encoder, decoder, train_loader, criterion, encoder_optimizer, decoder_optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估模型\n",
    "evaluate_model(encoder, decoder, test_loader, criterion, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入句子: how are you\n",
      "生成翻译: comment etes vous\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def translate_sentence(encoder, decoder, sentence, vocEng, vocFra, max_len=20):\n",
    "    # 1. 处理输入句子，将其转换为索引\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # 将输入句子分词，并转换为词汇表中的索引\n",
    "    indices = [vocEng.get(word, adding=False) for word in sentence.split(' ')]\n",
    "    input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # 形状 (1, seq_len)\n",
    "\n",
    "    # 2. 使用编码器得到隐藏状态\n",
    "    with torch.no_grad():\n",
    "        lengths = [input_tensor.shape[1]]  # 输入序列的长度\n",
    "        embedded = encoder.embedding(input_tensor)  # 获取嵌入表示\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        encoder_output, encoder_hidden = encoder.gru(packed_input)\n",
    "\n",
    "    # 3. 使用解码器逐步生成翻译\n",
    "    decoder_input = torch.tensor([[Vocabulary.SOS]]).to(device)  # 起始符，形状 (1, 1)\n",
    "    decoder_hidden = encoder_hidden  # 使用编码器的最后隐藏状态作为解码器的初始隐藏状态\n",
    "\n",
    "    translated_sentence = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            embedded = decoder.embedding(decoder_input)  # 获取解码器输入的嵌入表示\n",
    "            output, decoder_hidden = decoder.gru(embedded, decoder_hidden)  # 通过GRU获取输出\n",
    "            output = decoder.fc(output)  # 获取词汇表大小的输出\n",
    "            output = F.log_softmax(output, dim=-1)  # 获取词的概率分布\n",
    "\n",
    "        # 获取概率最高的词的索引\n",
    "        top1 = output.argmax(dim=-1).item()\n",
    "\n",
    "        # 如果生成结束符 EOS，则停止翻译\n",
    "        if top1 == Vocabulary.EOS:\n",
    "            break\n",
    "\n",
    "        # 添加生成的单词到翻译列表中\n",
    "        translated_sentence.append(vocFra.getword(top1))\n",
    "\n",
    "        # 准备下一个时间步的输入\n",
    "        decoder_input = torch.tensor([[top1]]).to(device)\n",
    "\n",
    "    return ' '.join(translated_sentence)\n",
    "\n",
    "# 示例输入句子\n",
    "input_sentence = \"how are you\"\n",
    "translated = translate_sentence(encoder, decoder, input_sentence, vocEng, vocFra)\n",
    "print(f\"输入句子: {input_sentence}\")\n",
    "print(f\"生成翻译: {translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepdac)",
   "language": "python",
   "name": "deepdac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
